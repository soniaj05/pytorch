{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5r0FYCoPKOjFIdziKSPw6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","#\n","#        -> 2.0              -> 0.65\n","# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n","#        -> 0.1              -> 0.1\n","#\n","#     scores(logits)      probabilities\n","#                           sum = 1.0\n","#\n","\n","# Softmax applies the exponential function to each element, and normalizes\n","# by dividing by the sum of all these exponentials\n","# -> squashes the output to be between 0 and 1 = probability\n","# sum of all probabilities is 1\n","def softmax(x):\n","    return np.exp(x) / np.sum(np.exp(x), axis=0)\n","\n","x = np.array([2.0, 1.0, 0.1])\n","outputs = softmax(x)\n","print('softmax numpy:', outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrKa8-tv1dzL","executionInfo":{"status":"ok","timestamp":1737715620234,"user_tz":-330,"elapsed":9352,"user":{"displayName":"Sona J","userId":"01357739765690311816"}},"outputId":"9b7d96db-b05c-49df-e821-c0296ac9438c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["softmax numpy: [0.65900114 0.24243297 0.09856589]\n"]}]},{"cell_type":"code","source":["x = torch.tensor([[2.0, 1.0, 0.1],[4.0,6.0,3.0]])\n","outputs = torch.softmax(x, dim=0) # along values along first axis\n","print('softmax torch:', outputs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vp50hEV1XWh","executionInfo":{"status":"ok","timestamp":1737716824888,"user_tz":-330,"elapsed":804,"user":{"displayName":"Sona J","userId":"01357739765690311816"}},"outputId":"1b8990f1-0cee-4531-b915-9d1d7b349908"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["softmax torch: tensor([[0.1192, 0.0067, 0.0522],\n","        [0.8808, 0.9933, 0.9478]])\n"]}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"flUxwvGR1QkJ","executionInfo":{"status":"ok","timestamp":1737717002738,"user_tz":-330,"elapsed":372,"user":{"displayName":"Sona J","userId":"01357739765690311816"}}},"outputs":[],"source":["\n","# Cross entropy\n","# Cross-entropy loss, or log loss, measures the performance of a classification model\n","# whose output is a probability value between 0 and 1.\n","# -> loss increases as the predicted probability diverges from the actual label\n","def cross_entropy(actual, predicted):\n","    loss = -np.sum(actual * np.log(predicted))\n","    return loss"]},{"cell_type":"code","source":["Y = np.array([1, 0, 0])\n","Y_pred_good = np.array([0.7, 0.2, 0.1])\n","Y_pred_bad = np.array([0.1, 0.3, 0.6])\n","l1 = cross_entropy(Y, Y_pred_good)\n","l2 = cross_entropy(Y, Y_pred_bad)\n","print(f'Loss1 numpy: {l1:.4f}')\n","print(f'Loss2 numpy: {l2:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tOo7xGB3bku","executionInfo":{"status":"ok","timestamp":1737717051851,"user_tz":-330,"elapsed":717,"user":{"displayName":"Sona J","userId":"01357739765690311816"}},"outputId":"1c104db6-12d8-49dd-a83a-6e095a960c32"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss1 numpy: 0.3567\n","Loss2 numpy: 2.3026\n"]}]},{"cell_type":"code","source":["loss=nn.CrossEntropyLoss()\n","y=torch.tensor([0])\n","Y_pred_bad=torch.tensor([[0.1,1.0,2.0]])\n","Y_pred_good=torch.tensor([[2.0,0.1,1.0]])\n","l1=loss(Y_pred_bad,y)\n","l2=loss(Y_pred_good,y)\n","print(l1)\n","print(l2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oycEp4JT3VDl","executionInfo":{"status":"ok","timestamp":1737718634318,"user_tz":-330,"elapsed":412,"user":{"displayName":"Sona J","userId":"01357739765690311816"}},"outputId":"0996e105-1fc1-457a-dc9d-0def5dbb9de5"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.3170)\n","tensor(0.4170)\n"]}]},{"cell_type":"code","source":["#__ is used to ignore the maximum value while storing the index in predictions1\n","_,predictions1 = torch.max(Y_pred_good, 1)\n","_,predictions2 = torch.max(Y_pred_bad, 1)\n","print(predictions1)\n","print(predictions2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqxN_1s9Gngb","executionInfo":{"status":"ok","timestamp":1737718913553,"user_tz":-330,"elapsed":390,"user":{"displayName":"Sona J","userId":"01357739765690311816"}},"outputId":"afe62626-036d-4447-8637-f68d8029fe3e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0])\n","tensor([2])\n"]}]},{"cell_type":"code","source":["class NeuralNet1(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(NeuralNet1, self).__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        # sigmoid at the end\n","        y_pred = torch.sigmoid(out)\n","        return y_pred\n","\n","model = NeuralNet1(input_size=28*28, hidden_size=5)\n","criterion = nn.BCELoss()\n","print(model)\n","print(criterion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzrnWNslGnUL","executionInfo":{"status":"ok","timestamp":1737721895747,"user_tz":-330,"elapsed":358,"user":{"displayName":"Sona J","userId":"01357739765690311816"}},"outputId":"597c147d-9f6a-4e10-b579-686ac714e0dc"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNet1(\n","  (linear1): Linear(in_features=784, out_features=5, bias=True)\n","  (relu): ReLU()\n","  (linear2): Linear(in_features=5, out_features=1, bias=True)\n",")\n","BCELoss()\n"]}]},{"cell_type":"code","source":["# Multiclass problem\n","class NeuralNet2(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet2, self).__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        # no softmax at the end\n","        return out\n","\n","model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"8xLQ1LNmM558","executionInfo":{"status":"ok","timestamp":1737720892699,"user_tz":-330,"elapsed":390,"user":{"displayName":"Sona J","userId":"01357739765690311816"}}},"execution_count":23,"outputs":[]}]}